rollout:
  backend: "auto"     # "auto" => vllm for LoRA, hf for Full FT; override with "vllm" or "hf"
  num_envs: 4
  num_workers: 2
  max_steps_per_episode: 8
  max_episodes_per_update: 16
  max_new_tokens: 256
  temperature: 0.7
  top_p: 0.95
  return_token_logprobs: true
  tools:
    enabled: true
    timeout_seconds: 20.0
    retry_attempts: 1
    allow_list: ["polygon","fmp","tavily","python","slack"]
  batch_size: 4
  minibatch_size: 1
